{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNhLycuXFvAOoW9JQ+Y/76C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khadijabensaad/ExpressMongoose/blob/main/un.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2DJgr_n4zzXL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "aisL9XvWLMcQ",
        "outputId": "1f05a5d0-ed03-4479-9a38-a9334386afe4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Analyse des modalités NIfTI (T1, T1CE, T2, FLAIR, seg)\n",
        "Objectif : déterminer quelles modalités sont les plus informatives pour la classification\n",
        "(ici: séparation voxel tumeur vs fond). Génère des courbes prouvant l'analyse.\n",
        "\n",
        "Usage:\n",
        " - Remplacer les chemins dans `paths` par vos fichiers .nii / .nii.gz\n",
        " - Lancer dans un Jupyter notebook ou en script\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, mutual_info_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "\n",
        "# -----------------------\n",
        "# CONFIG : chemins vers vos fichiers NIfTI\n",
        "# -----------------------\n",
        "paths = {\n",
        "    \"T1\":  \"data/T1.nii.gz\",\n",
        "    \"T1CE\":\"data/T1CE.nii.gz\",\n",
        "    \"T2\":  \"data/T2.nii.gz\",\n",
        "    \"FLAIR\":\"data/FLAIR.nii.gz\",\n",
        "    \"SEG\": \"data/seg.nii.gz\",   # segmentation binaire (0=fond, >0=tumeur)\n",
        "}\n",
        "\n",
        "# -----------------------\n",
        "# FONCTIONS UTILITAIRES\n",
        "# -----------------------\n",
        "def load_nifti(path):\n",
        "    img = nib.load(path)\n",
        "    data = img.get_fdata(dtype=np.float32)\n",
        "    return data\n",
        "\n",
        "def normalize_image(img, mask=None):\n",
        "    \"\"\"Z-score normalization using either whole image or masked voxels if mask provided.\"\"\"\n",
        "    if mask is not None:\n",
        "        vals = img[mask > 0]\n",
        "    else:\n",
        "        vals = img.flatten()\n",
        "    mean = np.mean(vals)\n",
        "    std = np.std(vals) if np.std(vals) > 0 else 1.0\n",
        "    imgn = (img - mean) / std\n",
        "    return imgn\n",
        "\n",
        "def compute_basic_stats(img, seg_mask):\n",
        "    \"\"\"Retourne mean_tumor, mean_background, ratio, std_tumor, snr approximation\"\"\"\n",
        "    tumor = img[seg_mask > 0]\n",
        "    bg = img[seg_mask == 0]\n",
        "    mean_t = np.mean(tumor) if tumor.size>0 else 0.0\n",
        "    mean_b = np.mean(bg) if bg.size>0 else 0.0\n",
        "    std_t = np.std(tumor) if tumor.size>0 else 0.0\n",
        "    ratio = (mean_t / (mean_b + 1e-9)) if mean_b != 0 else np.nan\n",
        "    snr = mean_t / (np.std(bg) + 1e-9) if bg.size>0 else np.nan\n",
        "    return {\"mean_tumor\": mean_t, \"mean_bg\": mean_b, \"ratio_t_b\": ratio, \"std_tumor\": std_t, \"snr\": snr}\n",
        "\n",
        "def compute_mutual_info(img, seg_mask, n_bins=64, sample_size=200000):\n",
        "    \"\"\"Approximate mutual information between intensity and seg label (discrete).\"\"\"\n",
        "    flat_img = img.flatten()\n",
        "    flat_seg = (seg_mask.flatten() > 0).astype(int)\n",
        "    # sample to speed up\n",
        "    idx = np.arange(flat_img.size)\n",
        "    if sample_size < flat_img.size:\n",
        "        idx = np.random.choice(idx, size=sample_size, replace=False)\n",
        "    a = flat_img[idx]\n",
        "    b = flat_seg[idx]\n",
        "    # discretize a into bins\n",
        "    a_disc = np.digitize(a, bins=np.linspace(np.min(a), np.max(a), n_bins))\n",
        "    mi = mutual_info_score(a_disc, b)\n",
        "    return mi\n",
        "\n",
        "# -----------------------\n",
        "# LOAD\n",
        "# -----------------------\n",
        "print(\"Chargement des images...\")\n",
        "for k,p in paths.items():\n",
        "    if not os.path.exists(p):\n",
        "        raise FileNotFoundError(f\"Fichier non trouvé : {p} (mettez le bon chemin)\")\n",
        "print(\"Tous les fichiers existent. Lecture en cours...\")\n",
        "\n",
        "img_T1   = load_nifti(paths[\"T1\"])\n",
        "img_T1CE = load_nifti(paths[\"T1CE\"])\n",
        "img_T2   = load_nifti(paths[\"T2\"])\n",
        "img_FLAIR= load_nifti(paths[\"FLAIR\"])\n",
        "img_seg  = load_nifti(paths[\"SEG\"])\n",
        "\n",
        "# Binariser la segmentation : 0 = fond, 1 = tumeur\n",
        "seg_mask = (img_seg > 0.5).astype(np.uint8)\n",
        "\n",
        "# -----------------------\n",
        "# NORMALISATION (Z-score par modalité)\n",
        "# -----------------------\n",
        "print(\"Normalisation (Z-score) par modalité...\")\n",
        "img_T1_n    = normalize_image(img_T1)\n",
        "img_T1CE_n  = normalize_image(img_T1CE)\n",
        "img_T2_n    = normalize_image(img_T2)\n",
        "img_FLAIR_n = normalize_image(img_FLAIR)\n",
        "\n",
        "modalities = {\n",
        "    \"T1\": img_T1_n,\n",
        "    \"T1CE\": img_T1CE_n,\n",
        "    \"T2\": img_T2_n,\n",
        "    \"FLAIR\": img_FLAIR_n\n",
        "}\n",
        "\n",
        "# -----------------------\n",
        "# STATISTIQUES BASIQUES & MI\n",
        "# -----------------------\n",
        "print(\"Calcul des statistiques basiques et mutual information...\")\n",
        "stats_list = []\n",
        "mi_list = {}\n",
        "for name, img in modalities.items():\n",
        "    st = compute_basic_stats(img, seg_mask)\n",
        "    mi = compute_mutual_info(img, seg_mask, n_bins=64, sample_size=200000)\n",
        "    st[\"modalite\"] = name\n",
        "    st[\"mutual_info\"] = mi\n",
        "    stats_list.append(st)\n",
        "    mi_list[name] = mi\n",
        "\n",
        "df_stats = pd.DataFrame(stats_list).set_index(\"modalite\")\n",
        "print(\"\\nStats par modalité :\\n\", df_stats.round(4))\n",
        "\n",
        "# -----------------------\n",
        "# EVALUATION par MODALITÉ : classification voxel tumeur vs fond (logistic regression)\n",
        "# -----------------------\n",
        "# Nous allons former un modèle simple par modalité : feature = intensity normalisée\n",
        "# puis mesurer l'AUC pour la capacité à séparer tumeur / fond.\n",
        "print(\"\\nEvaluation AUC par modalité (logistic regression sur voxels, échantillonnage équilibré)...\")\n",
        "\n",
        "def prepare_voxel_dataset(img, seg_mask, max_samples=200000):\n",
        "    flat_img = img.flatten()\n",
        "    flat_seg = (seg_mask.flatten() > 0).astype(int)\n",
        "    idx_tumor = np.where(flat_seg==1)[0]\n",
        "    idx_bg = np.where(flat_seg==0)[0]\n",
        "    n_pos = idx_tumor.size\n",
        "    n_neg = idx_bg.size\n",
        "    # équilibrer via sous-échantillonnage/oversampling si besoin\n",
        "    n_sample = min(max_samples//2, n_pos)  # max pos\n",
        "    if n_pos==0:\n",
        "        raise ValueError(\"Aucune voxels de tumeur dans la segmentation.\")\n",
        "    pos_idx = np.random.choice(idx_tumor, size=n_sample, replace=False)\n",
        "    neg_idx = np.random.choice(idx_bg, size=n_sample, replace=False)\n",
        "    idx = np.concatenate([pos_idx, neg_idx])\n",
        "    X = flat_img[idx].reshape(-1,1)\n",
        "    y = flat_seg[idx]\n",
        "    return X, y\n",
        "\n",
        "auc_results = {}\n",
        "roc_curves = {}\n",
        "\n",
        "for name, img in modalities.items():\n",
        "    X, y = prepare_voxel_dataset(img, seg_mask, max_samples=200000)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "    clf = LogisticRegression(max_iter=200, solver='lbfgs')\n",
        "    clf.fit(X_train, y_train)\n",
        "    probs = clf.predict_proba(X_test)[:,1]\n",
        "    auc = roc_auc_score(y_test, probs)\n",
        "    fpr, tpr, _ = roc_curve(y_test, probs)\n",
        "    auc_results[name] = auc\n",
        "    roc_curves[name] = (fpr, tpr)\n",
        "    print(f\"AUC {name}: {auc:.4f}\")\n",
        "\n",
        "# -----------------------\n",
        "# MODELE COMBINÉ (toutes modalités) + permutation importance approximée\n",
        "# -----------------------\n",
        "print(\"\\nEvaluation modèle combiné (modalités concaténées) — logistic regression multivariée...\")\n",
        "# préparer X avec les 4 intensities\n",
        "flat_shape = img_T1_n.shape\n",
        "flat_size = flat_shape[0]*flat_shape[1]*flat_shape[2]\n",
        "# pour la combinaison, échantillonnons voxels (équilibrés)\n",
        "def prepare_combined_dataset(modals_dict, seg_mask, n_each=50000):\n",
        "    flat_seg = (seg_mask.flatten() > 0).astype(int)\n",
        "    idx_tumor = np.where(flat_seg==1)[0]\n",
        "    idx_bg = np.where(flat_seg==0)[0]\n",
        "    n_pos = min(len(idx_tumor), n_each)\n",
        "    n_neg = min(len(idx_bg), n_each)\n",
        "    pos_idx = np.random.choice(idx_tumor, size=n_pos, replace=False)\n",
        "    neg_idx = np.random.choice(idx_bg, size=n_neg, replace=False)\n",
        "    idx = np.concatenate([pos_idx, neg_idx])\n",
        "    X = np.vstack([modals_dict[m].flatten()[idx] for m in modals_dict.keys()]).T\n",
        "    y = flat_seg[idx]\n",
        "    return X, y\n",
        "\n",
        "Xc, yc = prepare_combined_dataset(modalities, seg_mask, n_each=60000)\n",
        "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc, test_size=0.3, stratify=yc, random_state=42)\n",
        "clf_comb = LogisticRegression(max_iter=400, solver='lbfgs')\n",
        "clf_comb.fit(Xc_train, yc_train)\n",
        "probs_comb = clf_comb.predict_proba(Xc_test)[:,1]\n",
        "auc_comb = roc_auc_score(yc_test, probs_comb)\n",
        "print(f\"AUC modèle combiné : {auc_comb:.4f}\")\n",
        "\n",
        "# Permutation importance approximée : mesurer chute d'AUC quand on permute une colonne\n",
        "print(\"Calcul permutation importance (approx.)...\")\n",
        "perm_importance = {}\n",
        "rng = np.random.RandomState(42)\n",
        "baseline_auc = auc_comb\n",
        "for i, m in enumerate(list(modalities.keys())):\n",
        "    Xp = Xc_test.copy()\n",
        "    Xp[:, i] = rng.permutation(Xp[:, i])  # permute colonne i\n",
        "    auc_p = roc_auc_score(yc_test, clf_comb.predict_proba(Xp)[:,1])\n",
        "    perm_importance[m] = baseline_auc - auc_p  # perte d'AUC si modalité permutée\n",
        "\n",
        "# -----------------------\n",
        "# PLOTS : AUC par modalité, MI, ROC curves, Permutation importance\n",
        "# -----------------------\n",
        "plt.style.use('default')\n",
        "fig, axes = plt.subplots(2,2, figsize=(12,10))\n",
        "\n",
        "# AUC barplot\n",
        "ax = axes[0,0]\n",
        "names = list(auc_results.keys())\n",
        "aucs = [auc_results[n] for n in names]\n",
        "ax.bar(names, aucs)\n",
        "ax.set_ylim(0.0,1.0)\n",
        "ax.set_title(\"AUC par modalité (séparation voxels tumeur vs fond)\")\n",
        "ax.set_ylabel(\"AUC\")\n",
        "for i, v in enumerate(aucs):\n",
        "    ax.text(i, v+0.02, f\"{v:.3f}\", ha='center')\n",
        "\n",
        "# Mutual information barplot\n",
        "ax = axes[0,1]\n",
        "names_mi = list(mi_list.keys())\n",
        "mis = [mi_list[n] for n in names_mi]\n",
        "ax.bar(names_mi, mis)\n",
        "ax.set_title(\"Information mutuelle (intensité ⟷ segmentation)\")\n",
        "ax.set_ylabel(\"MI (bits approx.)\")\n",
        "for i, v in enumerate(mis):\n",
        "    ax.text(i, v+0.01, f\"{v:.3f}\", ha='center')\n",
        "\n",
        "# ROC curves (top 3 modalities)\n",
        "ax = axes[1,0]\n",
        "top_modalities = sorted(auc_results.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "for name, _ in top_modalities:\n",
        "    fpr, tpr = roc_curves[name]\n",
        "    ax.plot(fpr, tpr, label=f\"{name} (AUC={auc_results[name]:.3f})\")\n",
        "ax.plot([0,1],[0,1],'k--', linewidth=0.6)\n",
        "ax.set_title(\"ROC curves (top 3 modalités)\")\n",
        "ax.set_xlabel(\"False Positive Rate\")\n",
        "ax.set_ylabel(\"True Positive Rate\")\n",
        "ax.legend()\n",
        "\n",
        "# Permutation importance\n",
        "ax = axes[1,1]\n",
        "mods = list(perm_importance.keys())\n",
        "vals = [perm_importance[m] for m in mods]\n",
        "ax.bar(mods, vals)\n",
        "ax.set_title(\"Permutation importance (chute d'AUC si permuté)\")\n",
        "ax.set_ylabel(\"Perte d'AUC\")\n",
        "for i, v in enumerate(vals):\n",
        "    ax.text(i, v+0.001, f\"{v:.4f}\", ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# -----------------------\n",
        "# RÉSULTATS RÉCAPITULATIFS\n",
        "# -----------------------\n",
        "print(\"\\n--- RÉSUMÉ ---\")\n",
        "print(\"AUC par modalité :\")\n",
        "for k,a in auc_results.items():\n",
        "    print(f\"  {k}: AUC = {a:.4f}, MI = {mi_list[k]:.4f}, mean_tumor={df_stats.loc[k,'mean_tumor']:.3f}, mean_bg={df_stats.loc[k,'mean_bg']:.3f}\")\n",
        "\n",
        "print(f\"\\nModèle combiné AUC = {auc_comb:.4f}\")\n",
        "print(\"Permutation importance (perte d'AUC si permutée) :\")\n",
        "for k,v in perm_importance.items():\n",
        "    print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "# -----------------------\n",
        "# CONSEILS D'INTERPRÉTATION (affichés ici pour référence)\n",
        "# -----------------------\n",
        "# - Une modalité avec AUC élevé et MI élevé sépare bien tumeur/fond — utile pour classification & génération.\n",
        "# - Si la modalité T1CE (par exemple) a la meilleure AUC → elle est cruciale pour la classification\n",
        "# - Le modèle combiné doit dépasser les modalités individuelles ; la permutation importance\n",
        "#   indique quelles modalités contribuent le plus.\n",
        "#\n",
        "# Vous pouvez ensuite :\n",
        "# - utiliser les modalités top-N pour entraîner votre CNN3D + EfficientNet (ex : Empiler ces canaux en entrée)\n",
        "# - ou utiliser Med-DDPM conditionné sur ces canaux pour la simulation post-traitement.\n",
        "#\n",
        "# Fin du script.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "9CkNpVTR0le4",
        "outputId": "5ffcc733-4703-4f7b-aa05-737071d22265"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement des images...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Fichier non trouvé : data/T1.nii.gz (mettez le bon chemin)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2263076791.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Fichier non trouvé : {p} (mettez le bon chemin)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tous les fichiers existent. Lecture en cours...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Fichier non trouvé : data/T1.nii.gz (mettez le bon chemin)"
          ]
        }
      ]
    }
  ]
}